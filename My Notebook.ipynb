{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # pandas data frame\n",
    "import numpy as np # numpy numerical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame (pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('', sep=':', header= 0, names=[header list] , index_col =0 or ['',''])\n",
    "df.shape\n",
    "df.dtypes\n",
    "type(df['column'][0])\n",
    "df.info()\n",
    "df.nunique()\n",
    "df.describe()\n",
    "sum(df.duplicated()) # Check number of duplicates\n",
    "sum(df.isnull().any(axis=1)) # Count null values\n",
    "df_08['column'].value_counts() # Count unique values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operation on data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_08.drop(['', ''], axis=1, inplace=True) # drop columns\n",
    "df.drop_duplicates(inplace=True) # Drop duplicates in row\n",
    "df_18.dropna(inplace=True) # Drop null value\n",
    "df.fillna(df.mean(),inplace=True) # use means to fill in missing values\n",
    "null_data = df[df.isnull().any(axis=1)]\n",
    "df.rename(columns={'old':'new'},inplace = True) # rename column\n",
    "df.rename(columns=lambda x: x.strip().lower().replace(\" \", \"_\"), inplace=True) # rename all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract int from strings\n",
    "df['column'] = df['column'].str.extract('(\\d+)').astype(int)\n",
    "\n",
    "hb = df[df['column'].str.contains('/')]\n",
    "# create two copies of the dataframe\n",
    "df1 = hb.copy()  # data on first string\n",
    "df2 = hb.copy()  # data on second string\n",
    "# columns to split by \"/\"\n",
    "split_columns = ['','']\n",
    "# apply split function to each column of each dataframe copy\n",
    "for c in split_columns:\n",
    "    df1[c] = df1[c].apply(lambda x: x.split(\"/\")[0])\n",
    "    df2[c] = df2[c].apply(lambda x: x.split(\"/\")[1])\n",
    "\n",
    "new_rows = df1.append(df2)\n",
    "# drop the original rows\n",
    "df.drop(hb.index, inplace=True)\n",
    "# add in our newly separated rows\n",
    "df = df.append(new_rows, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data frame\n",
    "df.to_csv('xyz.csv', index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexing and Selecting\n",
    "for i, v in enumerate(df.columns):\n",
    "    print(i, v)\n",
    "\n",
    "df_1 = df.loc[:,'':''] # locate column with name include last\n",
    "df_1 = df.iloc[:,1:2] # locate with index number excuding last\n",
    "df_2 = df.iloc[:,np.r_[:2,12:22]] # locate with descrete index excuding last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove \"_mean\" from column names\n",
    "new_labels = []\n",
    "for col in df.columns:\n",
    "    if '_mean' in col:\n",
    "        new_labels.append(col[:-5])  # exclude last 6 characters\n",
    "    else:\n",
    "        new_labels.append(col)\n",
    "\n",
    "# new labels for our columns\n",
    "new_labels\n",
    "\n",
    "# assign new labels to columns in dataframe\n",
    "df.columns = new_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "% matplotlib inline\n",
    "df=pd.read_csv('.csv')\n",
    "df.hist()\n",
    "df['column_name'].hist()\n",
    "df['column_name'].value_counts().plot(kind='bar')\n",
    "df['column_name'].value_counts().plot(kind='pie',figsize=(8,8))\n",
    "pd.plotting.scatter_matrix(df,figsize=(15,15)) # histrogram and scatter plot of each variable\n",
    "df.plot(x='',y='',kind='scatter')\n",
    "df['column_name'].plot(kind='box')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['timecolumn']=pd.to_datetime(df.timecolumn)\n",
    "df.mean()\n",
    "df[df['storeC']== df['storeC'].min()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add new label column\n",
    "color_red = np.repeat('red',red_df.shape[0])\n",
    "red_df['color'] = color_red\n",
    "\n",
    "#Append two data frames\n",
    "new_df = red_df.append(white_df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df1, df4], axis=1)\n",
    "df.groupby('parameters').mean()\n",
    "df.groupby(['parameters','2ndparameter'],as_index =False)['display specific column'].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorize the column of data frame into 4 equal level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the min, 25%, 50%, 75%, max pH values with Pandas describe\n",
    "df['columnname'].describe()\n",
    "# Bin edges that will be used to \"cut\" the data into groups\n",
    "bin_edges = [ , , , , ] # Fill in this list with five values you just found\n",
    "# Labels for the four acidity level groups\n",
    "bin_names = [ , , , ] # Name each column level category\n",
    "# Creates acidity_levels column\n",
    "df['column_levels'] = pd.cut(df['columnname'], bin_edges, labels=bin_names)\n",
    "# Checks for successful creation of this column\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Queries from dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting malignant records in cancer data\n",
    "df_m = df[df['diagnosis'] == 'M']\n",
    "df_m = df.query('diagnosis == \"M\"')\n",
    "\n",
    "# selecting records of people making over $50K\n",
    "df_a = df[df['income'] == ' >50K']\n",
    "df_a = df.query('income == \" >50K\"')\n",
    "\n",
    "# selecting records in cancer data with radius greater than the median\n",
    "df_h = df[df['radius'] > 13.375]\n",
    "df_h = df.query('radius > 13.375')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
