{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangle Report\n",
    "\n",
    "## Objective of the Project\n",
    "\n",
    "- [Data Gathering](#gathering)\n",
    "- [Data Assessing](#assessing)\n",
    "- [Data Cleaning](#cleaning)\n",
    "- [Storing and Acting on Wrangled Data](#acting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='gathering'></a>\n",
    "### Data Gathering\n",
    "\n",
    "Data always comes from different sources. In this project, Data is collected from 3 different sources. The twitter archive is a good source of data but it does not contain complete information such as tweets count , or retweets count. We'll use tweepy to to get data from Twitter API.\n",
    "\n",
    "First load the archive data using panda's `read_csv` method. Our data contains alot of rows to visualy assess few (3) rows, take __transpose__ using `.head(3).T`\n",
    "\n",
    "We have other data set in the form of tab seperated values of image prediction of each dogs for each `tweet_id`. We  used request library to download the tab seprated values of image prediction.  As our downloaded or requested file was .tsv, We used same pandas `.read_csv` method but this time used `sep='\\t'` in the arguments to tell the pandas that it is tab seprated file\n",
    "\n",
    "To gather data from Twitter API, first we have to configure and set the environment for requesting the data from Twitter API\n",
    "We 'll use pandas `.read_json` method using `lines=True` to read each line as row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='assessing'></a>\n",
    "### Data Assessing\n",
    "#### Visual Assessment\n",
    "To Assess our data visualy we'll set the pandas option for displaying every row and column as by defaut pandas truncate few column to fit the data in frame\n",
    "\n",
    "\n",
    "```\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.options.display.max_colwidth = 10000\n",
    "```\n",
    "#### Programmatic Assessment\n",
    "\n",
    "After assessing the data frames visually its good practice to assess them programmaticly to check the data types and number of non null values panda's `.info()` method used and statistical description or summary of numeric data is generated using `.describe()` method. There were alot of missing values and wrong data types as well as extra or unecessary columns and dog style was in 4 different columns. While checking the `values_count()` of names of the dog it was assessed that there were alot of wrong name such as `the, a, an, all, e.t.c`. For duplicated rows `.duplicated` method was used. Following are the Quality and Tidiness Issue that was addressed in this project\n",
    "\n",
    "#### Quality Issue\n",
    "1. Some tweets do not contain an image\n",
    "2. Timestamp is string and should be datetime\n",
    "3. Tweet id should be string not integer\n",
    "4. Dog stage and img_num are string they must be categorical\n",
    "5. p1, p2, and p3 are inconsistent\n",
    "6. Name column contains articles instead of names\n",
    "7. Remove retweets\n",
    "8. Some columns are extraneous and must be deleted\n",
    "\n",
    "\n",
    "#### Tidiness Issue\n",
    "1. Dog breed could be in one column instead of 4\n",
    "2. All the dataframes could be fit into 1 master data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='cleaning'></a>\n",
    "### Data Cleaning\n",
    "Before starting the cleaning proccess create the copies of each dataframes using `.copy()` method\n",
    "\n",
    "##### Tidiness Issue 1\n",
    "In twitter_enhanced dog stage are in 4 different columns the must be in one column. used list expression to generate a list using four different column. and then add the new column and drop the prevous four columns of `'doggo', 'floofer', 'pupper', 'puppo`\n",
    "\n",
    "\n",
    "##### Tidiness Issue 2\n",
    "also deals __Quality issue 1__\n",
    "\n",
    "In order to satisfy the project motivation which was prediction of dog breed from image. Inner Merge the dataset on tweet_id was required used pandas `.merge` method and perform `inner join` on `tweet_id` of all 3 dataframes. This Tidiness Issue solution also solved our 1st quality issue now our all tweets have image as well\n",
    "\n",
    "##### Quality Issue 2,3,4\n",
    "Different 3 qulaity issue was related to the data types of few columns. Change the data types of column, timestamp should be in  DateTime and used panda's `.to_datetime` method to convert into datetime type. Although tweet id are numbers but they are not only numeric values they are specific for each id thus they should be in string object not integer and img_num should be categorical as some have 1, 2,3, or only 4 number in that column\n",
    "\n",
    "\n",
    "##### Quality Issue 5\n",
    "There was inconsistency and everything should be in lower cases in `'p1', 'p2' and 'p3'` so we replaced all '_' and '-' with spaces and we used str.lower().str.replace('_', ' ') for this purpose\n",
    "\n",
    "##### Quality Issue 6\n",
    "As some of dog names were wrong. from visual assessment it was noted that wrong name was in lower case. first we detect the names that start with lower case then we removed the wrong names from the name column\n",
    "\n",
    "\n",
    "##### Quality Issue 7\n",
    "few tweets were not real ratings about the dogs they were just retweets. Remove reweets from the data set using `isnull` method of pandas\n",
    "\n",
    "##### Quality Issue 8\n",
    "In order to make our master dataframe contains only valid or non null rows and columns removed extra columns `'in_reply_to_user_id','retweeted_status_id','retweeted_status_user_id', 'retweeted_status_timestamp','in_reply_to_status_id'`  from the master dataframe using panda's `.drop` method. Following is the `info` of the final master dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1964 entries, 0 to 2058\n",
      "Data columns (total 22 columns):\n",
      "tweet_id              1964 non-null object\n",
      "timestamp             1964 non-null datetime64[ns]\n",
      "source                1964 non-null object\n",
      "text                  1964 non-null object\n",
      "expanded_urls         1964 non-null object\n",
      "rating_numerator      1964 non-null int64\n",
      "rating_denominator    1964 non-null int64\n",
      "name                  1866 non-null object\n",
      "stage                 363 non-null category\n",
      "jpg_url               1964 non-null object\n",
      "img_num               1964 non-null category\n",
      "p1                    1964 non-null object\n",
      "p1_conf               1964 non-null float64\n",
      "p1_dog                1964 non-null bool\n",
      "p2                    1964 non-null object\n",
      "p2_conf               1964 non-null float64\n",
      "p2_dog                1964 non-null bool\n",
      "p3                    1964 non-null object\n",
      "p3_conf               1964 non-null float64\n",
      "p3_dog                1964 non-null bool\n",
      "retweet_count         1964 non-null int64\n",
      "favorite_count        1964 non-null int64\n",
      "dtypes: bool(3), category(2), datetime64[ns](1), float64(3), int64(4), object(9)\n",
      "memory usage: 384.0+ KB\n"
     ]
    }
   ],
   "source": [
    "clean_master_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='acting'></a>\n",
    "### Storing and Acting on Wrangled Data\n",
    "Now our final, clean and tidy, dataset was ready. its time to store the dataframe in csv. first we reset the indexes using `.reset_index` method and then stored the `twitter_master.csv` using pandas `.to_csv` method. Now our data is ready for analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
