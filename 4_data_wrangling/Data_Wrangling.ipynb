{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data_Wrangling.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdDI5RYiEdsz",
        "colab_type": "text"
      },
      "source": [
        "# Data Wrangling Summary\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ib-gFw8ACOYf",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "### Gather\n",
        "* Depending on the source of your data, and what format it's in, the steps in gathering data vary.\n",
        "* High-level gathering process: obtaining data (downloading a file from the internet, scraping a web page, querying an API, etc.) and importing that data into your programming environment (e.g., Jupyter Notebook).\n",
        "\n",
        "### Assess\n",
        "\n",
        "Assess data for:\n",
        "* **Quality:** issues with content. Low quality data is also known as dirty data.\n",
        "* **Tidiness:** issues with structure that prevent easy analysis. Untidy data is also known as messy data. Tidy data requirements:\n",
        "  - Each variable forms a column.\n",
        "  - Each observation forms a row.\n",
        "  - Each type of observational unit forms a table.\n",
        "\n",
        "### Types of assessment:\n",
        "* **Visual assessment:** scrolling through the data in your preferred software application (Google Sheets, Excel, a text editor, etc.).\n",
        "* **Programmatic assessment:** using code to view specific portions and summaries of the data (pandas' `head`, `tail`, and `info` methods, for example).\n",
        "\n",
        "### Clean\n",
        "\n",
        "### Types of cleaning:\n",
        "* Manual (not recommended unless the issues are single occurrences)\n",
        "* Programmatic\n",
        "The programmatic data cleaning process:\n",
        "    \n",
        "    * **Define:** convert our assessments into defined cleaning tasks. These definitions also serve as an instruction list so others (or yourself in the future) can look at your work and reproduce it.\n",
        "    * **Code:** convert those definitions to code and run that code.\n",
        "    * **Test:** test your dataset, visually or with code, to make sure your cleaning operations worked.\n",
        "      \n",
        "  Always make copies of the original pieces of data before cleaning!\n",
        "\n",
        "### Reassess and Iterate\n",
        "After cleaning, always reassess and iterate on any of the data wrangling steps if necessary.\n",
        "\n",
        "### Store (Optional)\n",
        "Store data, in a file or database for example, if you need to use it in the future."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_T7uY6Y7COsH",
        "colab_type": "text"
      },
      "source": [
        "## Gathering\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjTBZwg2OOho",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import zipfile\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6N98pcpOU7V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with zipfile.ZipFile('/content/drive/My Drive/Colab Notebooks/Data Wrangling/armenian-online-job-postings.zip','r') as myzip:\n",
        "  myzip.extractall()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JacY8whW_1Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df=pd.read_csv('/content/online-job-postings.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPMv_GRAxP43",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4db-E9srM8W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.head()\n",
        "df.tail()\n",
        "# df.info()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BivKyLlqL0zy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "url= 'https://pandas.pydata.org/pandas-docs/stable/reference/index.html'\n",
        "response = request.get(url)\n",
        "#save html to file\n",
        "with open(\"file_name.html\", mode ='wb') as file:\n",
        "  file.write(response.content)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BhSksIuuKun",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# List of dictionaries to build file by file and later convert to a DataFrame\n",
        "df_list = []\n",
        "folder = 'rt_html'\n",
        "for movie_html in os.listdir(folder):\n",
        "    with open(os.path.join(folder, movie_html)) as file:\n",
        "        soup= BeautifulSoup(file,'lxml')\n",
        "        title = soup.find('title').contents[0][:-len(' - Rotten Tomatoes')]\n",
        "        audience_score = soup.find('div',class_='audience-score meter').find('span').contents[0][:-1]\n",
        "        num_audience_ratings = soup.find('div', class_ ='audience-info hidden-xs superPageFontColor')\n",
        "        num_audience_ratings=num_audience_ratings.find_all('div')[1].contents[2].strip().replace(',', '')\n",
        "\n",
        "        # Note: a correct implementation may take ~15 seconds to run\n",
        "        \n",
        "        \n",
        "        # Append to list of dictionaries\n",
        "        df_list.append({'title': title,\n",
        "                        'audience_score': int(audience_score),\n",
        "                        'number_of_audience_ratings': int(num_audience_ratings)})\n",
        "df = pd.DataFrame(df_list, columns = ['title', 'audience_score', 'number_of_audience_ratings'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1678SFGGuLBy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_solution = pd.read_pickle('df_solution.pkl')\n",
        "df.sort_values('title', inplace = True)\n",
        "df.reset_index(inplace = True, drop = True)\n",
        "df_solution.sort_values('title', inplace = True)\n",
        "df_solution.reset_index(inplace = True, drop = True)\n",
        "pd.testing.assert_frame_equal(df, df_solution)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNEDpyQ4vvex",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make directory if it doesn't already exist\n",
        "folder_name = 'ebert_reviews'\n",
        "if not os.path.exists(folder_name):\n",
        "    os.makedirs(folder_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1OvDSO6vwAz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ebert_review_urls = ['https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9900_1-the-wizard-of-oz-1939-film/1-the-wizard-of-oz-1939-film.txt',\n",
        "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad991e_99-the-godfather-part-ii/99-the-godfather-part-ii.txt',\n",
        "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad991e_100-battleship-potemkin/100-battleship-potemkin.txt']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCtYlx943sfn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# downloading text files\n",
        "for url in ebert_review_urls:\n",
        "    response=requests.get(url)\n",
        "    with open(os.path.join(folder_name,url.split('/')[-1]), mode ='wb') as file:\n",
        "        file.write(response.content)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ok6b1f8qCTru",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQoFEdIw3twO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob\n",
        "\n",
        "# List of dictionaries to build file by file and later convert to a DataFrame\n",
        "df_list = []\n",
        "for ebert_review in glob.glob('ebert_reviews/*.txt'):\n",
        "    with open(ebert_review, encoding='utf-8') as file:\n",
        "        title = file.readline()[:-1]\n",
        "        # Your code here\n",
        "        review_url = file.readline()[:-1]\n",
        "        review_text = file.read()\n",
        "\n",
        "        # Append to list of dictionaries\n",
        "        df_list.append({'title': title,\n",
        "                        'review_url': review_url,\n",
        "                        'review_text': review_text})\n",
        "df = pd.DataFrame(df_list, columns = ['title', 'review_url', 'review_text'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZaeY-NrCcmf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import wptools\n",
        "import os\n",
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "# List of dictionaries to build and convert to a DataFrame later\n",
        "df_list = []\n",
        "image_errors = {}\n",
        "for title in title_list:\n",
        "    try:\n",
        "        # This cell is slow so print ranking to gauge time remaining\n",
        "        ranking = title_list.index(title) + 1\n",
        "        print(ranking)\n",
        "        page = wptools.page(title, silent=True)\n",
        "        # Your code here (three lines)\n",
        "        images = page.get().data['image']\n",
        "        # First image is usually the poster\n",
        "        first_image_url = images[0]['url']\n",
        "        r = requests.get(first_image_url)\n",
        "        # Download movie poster image\n",
        "        i = Image.open(BytesIO(r.content))\n",
        "        image_file_format = first_image_url.split('.')[-1]\n",
        "        i.save(folder_name + \"/\" + str(ranking) + \"_\" + title + '.' + image_file_format)\n",
        "        # Append to list of dictionaries\n",
        "        df_list.append({'ranking': int(ranking),\n",
        "                        'title': title,\n",
        "                        'poster_url': first_image_url})\n",
        "    \n",
        "    # Not best practice to catch all exceptions but fine for this short script\n",
        "    except Exception as e:\n",
        "        print(str(ranking) + \"_\" + title + \": \" + str(e))\n",
        "        image_errors[str(ranking) + \"_\" + title] = images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNW1N4sxCc_s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sqlalchemy import create_engine\n",
        "# Create SQLAlchemy Engine and empty bestofrt database\n",
        "# bestofrt.db will not show up in the Jupyter Notebook dashboard yet\n",
        "engine = create_engine('sqlite:///bestofrt.db')\n",
        "# Store cleaned master DataFrame ('df') in a table called master in bestofrt.db\n",
        "# bestofrt.db will be visible now in the Jupyter Notebook dashboard\n",
        "df.to_sql('master', engine, index=False)\n",
        "Read the brand new data in that database back into a pandas DataFrame.\n",
        "df_gather = pd.read_sql('SELECT * FROM master', engine)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_gDTlYovJ_f",
        "colab_type": "text"
      },
      "source": [
        "## Assessing\n",
        "**Assessing** your data is the second step in data wrangling. When assessing, you're like a detective at work, inspecting your dataset for two things: data quality issues (i.e. content issues) and lack of tidiness (i.e. structural issues).\n",
        "\n",
        "Assessing is the precursor to cleaning. You can't clean something that you don't know exists! In this lesson, you'll learn to identify and categorize common data quality and tidiness issues. This lesson is the shortest and most \"hands-off\" code-wise of all four in the course because of the passive nature of assessing relative to gathering and cleaning. We have tried to include quizzes wherever possible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofn0ytrqSpDc",
        "colab_type": "text"
      },
      "source": [
        "You can assess data for:\n",
        "\n",
        "- **Quality:** issues with content. Low quality data is also known as dirty data.\n",
        "- **Tidiness:** issues with structure that prevent easy analysis.\n",
        "\n",
        "Untidy data is also known as messy data. Tidy data requirements:\n",
        "- Each variable forms a column.\n",
        "- Each observation forms a row.\n",
        "- Each type of observational unit forms a table.\n",
        "\n",
        "...using two types of assessment:\n",
        "\n",
        "1. Visual assessment: scrolling through the data in your preferred software application (Google Sheets, Excel, a text editor, etc.).\n",
        "2. Programmatic assessment: using code to view specific portions and summaries of the data (pandas' head, tail, and info methods, for example).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gL4obR0VCyDt",
        "colab_type": "text"
      },
      "source": [
        "### Visual Assesment\n",
        "#### Data Quality Dimensions\n",
        "\n",
        "Data quality dimensions help guide your thought process while assessing and also cleaning. The four main data quality dimensions are:\n",
        "\n",
        "- **Completeness:** do we have all of the records that we should? Do we have missing records or not? Are there specific rows, columns, or cells missing?\n",
        "- **Validity:** we have the records, but they're not valid, i.e., they don't conform to a defined schema. A schema is a defined set of rules for data. These rules can be real-world constraints (e.g. negative height is impossible) and table-specific constraints (e.g. unique key constraints in tables).\n",
        "- **Accuracy:** inaccurate data is wrong data that is valid. It adheres to the defined schema, but it is still incorrect. Example: a patient's weight that is 5 lbs too heavy because the scale was faulty.\n",
        "- **Consistency:** inconsistent data is both valid and accurate, but there are multiple correct ways of referring to the same thing. Consistency, i.e., a standard format, in columns that represent the same data across tables and/or within tables is desired."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qttp0KFIEpOr",
        "colab_type": "text"
      },
      "source": [
        "### Programmatic Assesment\n",
        "These are the programmatic assessment methods in pandas that you will probably use most often:\n",
        "\n",
        "* .head (DataFrame and Series)\n",
        "* .tail (DataFrame and Series)\n",
        "* .sample (DataFrame and Series)\n",
        "* .info (DataFrame only)\n",
        "* .describe (DataFrame and Series)\n",
        "* .value_counts (Series only)\n",
        "* Various methods of indexing and selecting data (.loc and bracket notation with/without boolean indexing, also .iloc)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFzzBA7mC-5i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}